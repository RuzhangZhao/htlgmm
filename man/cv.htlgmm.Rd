% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/htlgmm.R
\name{cv.htlgmm}
\alias{cv.htlgmm}
\title{Cross validation for htlgmm.}
\usage{
cv.htlgmm(
  y,
  Z,
  W = NULL,
  ext_study_info = NULL,
  A = "default",
  penalty_type = "lasso",
  family = "gaussian",
  initial_with_type = "lasso",
  beta_initial = NULL,
  weight_adaptivelasso = NULL,
  alpha = NULL,
  hat_thetaA = NULL,
  V_thetaA = NULL,
  use_offset = TRUE,
  robust = FALSE,
  remove_penalty_Z = FALSE,
  remove_penalty_W = FALSE,
  inference = "default",
  fix_C = NULL,
  fix_inv_C = NULL,
  refine_C = FALSE,
  sqrt_matrix = "cholesky",
  use_cv = TRUE,
  type_measure = "default",
  nfolds = 10,
  foldid = NULL,
  fix_lambda = NULL,
  lambda_list = NULL,
  nlambda = 100,
  lambda.min.ratio = 1e-04,
  tune_ratio = FALSE,
  fix_ratio = NULL,
  ratio_list = NULL,
  tune_weight = FALSE,
  fix_weight = NULL,
  weight_list = NULL,
  tune_weight_method = "mshrink",
  gamma_adaptivelasso = 1/2,
  use_sparseC = TRUE,
  seed.use = 97,
  output_all_betas = FALSE
)
}
\arguments{
\item{y}{The variable of interest, which can be continuous or binary.}

\item{Z}{The overlapping features in both main and external studies.}

\item{W}{The unmatched features only in main study, the default is NULL.}

\item{ext_study_info}{The trained model from external study, including estimated coefficients, and estimated variance-covariance matrix.
The 'ext_study_info' is in the format of list. The first item is 'Coeff', the second item is 'Covariance'.
E.g. ext_study_info = list(list("Coeff"=coeff,"Covariance"=covariance))}

\item{A}{The covariates for study-specific adjustment. The default is 'default', which is 'NULL' for 'gaussian' family, '1' for 'binomial' family.
Other than c('default',NULL,1), A must be a matrix whose dimension is the same as the sample dimension or Z and W.
For continuous variable, we suggest scaling the features Z, W to eliminate intercept term.  If 'A = NULL', there is no intercept term included.
For binary variable, we use intercept term by 'A=1' to adjust for different binary trait ratios in main and external studies.
If there is only intercept term in A, we use 'A=1'.
A are the features working for adjustment in reduced model, but A is not summarized in summary statistics(input:ext_study_info).}

\item{penalty_type}{The penalty type for htlgmm, chosen from c("none","lasso","adaptivelasso","ridge","elasticnet"). The default is "lasso".
If 'penalty_type = 'none' ', we use without penalty. (For continuous y, we use ordinary least square, and for binary y, we use logistic regression without penalty.)}

\item{family}{The family is chosen from c("gaussian","binomial"). Linear regression for "gaussian" and logistic regression for "binomial".}

\item{initial_with_type}{Get initial estimation for beta using main study data only
by cross validation using penalty regression, chosen from c("ridge","lasso","glm"). The default is "lasso". If penalty_type = 'glm',
for continuous y, we use ordinary least square, and for binary y, we use logistic regression without penalty.)}

\item{beta_initial}{The initial estimation for beta if a consistent estimator is available.
E.g., one may input htlgmm result as beta_initial for more rounds to refine the final estimation.
The default is NULL, and main study is used for initial estimation according to 'initial_with_type'.}

\item{weight_adaptivelasso}{The weight of adaptive lasso when using penalty_type = 'adaptivelasso'. The default is NULL. When using default weight_adaptivelasso, user may follow the instruction from 'Zou, H. (2006). The adaptive lasso and its oracle properties.'
The input of 'weight_adaptivelasso' can either be with all features (the same length as beta_initial) or without intercept.}

\item{alpha}{The elasticnet mixing parameter, between 0 and 1, which is corresponding to the alpha for glmnet. Only used when penalty_type == 'elasticnet'.}

\item{hat_thetaA}{If A is not NULL, one can provide hat_thetaA as the input. If 'hat_thetaA = NULL', we estimate hat_thetaA with glm by main study.}

\item{V_thetaA}{If A is not NULL, one can provide V_thetaA as the input. If 'V_thetaA = NULL', we estimate V_thetaA with glm by main study.}

\item{use_offset}{Whether to use offset regarding the external model estimated coefficient. The default is FALSE.}

\item{robust}{Whether to apply sandwich formula to compute the variance-covariance matrix of hat_thetaA.The default is FALSE.
For coxph model, robust is also about whether we apply the robust variance for the estimating equations.}

\item{remove_penalty_Z}{Not penalize Z if it is TRUE. The default is FALSE.}

\item{remove_penalty_W}{Not penalize W if it is TRUE. The default is FALSE.}

\item{inference}{Whether to do inference without penalty or post-selection inference with adaptive lasso penalty. The default is 'default', which is TRUE when penalty_type = 'none' or 'adaptivelasso', and FALSE otherwise.}

\item{fix_C}{When fix_C = NULL, the optimal C is computed. When user wants to customize the fix_C, please match its dimension as dim(A)+2*dim(Z)+dim(W) and make sure it is positive definite.}

\item{fix_inv_C}{When fix_inv_C = NULL, the optimal C is computed. When user wants to customize the fix_inv_C, please match its dimension as dim(A)+2*dim(Z)+dim(W) and make sure it is positive definite. When fix_C and fix_inv_C are both given, the fix_C will be used.}

\item{refine_C}{When computing the variance, whether recompute the weighting matrix C using final estimated beta.}

\item{sqrt_matrix}{The method to split weighting matrix into square root matrix. Select from c('svd','cholesky'), where 'cholesky' generates faster computation.}

\item{use_cv}{Whether to use cross validation to determine the best lambda (or ratio).}

\item{type_measure}{Select from c("default", "mse", "deviance", "auc"). Default is mse(liner), auc(logistic). 'deviance' is another choice for binary y.}

\item{nfolds}{The fold number for cross validation. Only work for use_cv = TRUE.The default is 10.}

\item{foldid}{An optional vector of values with the length of sample size, identifying what fold each observation is in. If supplied, nfolds can be missing.}

\item{fix_lambda}{Without cross validation, fix the lambda. The default is NULL.}

\item{lambda_list}{Customize the input lambda list for validation. The default is NULL to generate lambda list according to glmnet.}

\item{nlambda}{The number of lambda values - default is 100.}

\item{lambda.min.ratio}{Smallest value for lambda, as a fraction of lambda.max. The default is 0.0001.}

\item{tune_ratio}{Whether to use two-lambda stratgey. The default is FALSE. This is not applied to coxph model.}

\item{fix_ratio}{The fixed ratio for two-lambda strategy. The ratio is multiplied for Z features. The default is NULL. If it is NULL, select the best ratio via cross validation.}

\item{ratio_list}{The ratio list if it is preset. The default is NULL and ratio list will be generated.}

\item{tune_weight}{Whether to assign tuning weight for weighting matrix of external study part. The default is FALSE. This is not applied to coxph model.}

\item{fix_weight}{The fixed weight for for weighting matrix of external study part. The default is NULL. If it is NULL, select the best weight via cross validation.}

\item{weight_list}{The weight list if it is preset. The default is NULL and weight list will be generated.}

\item{tune_weight_method}{Method for weight tuning. The default is 'multiplicative shrinkage', which can also be used as 'mshrink' or 'ms'. The other choice is 'ridge'.}

\item{gamma_adaptivelasso}{The gamma for adaptive lasso. Select from c(1/2,1,2). The default is 1/2.}

\item{use_sparseC}{Whether to use approximate version of weighting matrix C.
If approximation, use the diagonal of inverse of C(inv_C) to approximate the inv_C. The default is TRUE.
When main study sample size is limited, use_sparseC = TRUE is recommended.
When main study sample size is large enough, use_sparseC = FALSE is recommended.}

\item{seed.use}{The seed for  97.}

\item{output_all_betas}{output_all_betas}
}
\value{
\itemize{
 \item{beta:} The target coefficient estimation, the features will go in the order of (A,Z,W).
 \item{lambda_list:} The lambda list for cross validation.
 \item{ratio_list:} The ratio list for cross validation.
 \item{fix_lambda:} If the fix_lambda is not null, we output fix_lambda.
 \item{fix_ratio:} If the fix_ratio is not null, we output fix_ratio.
 \item{lambda_min:} The selected best lambda by cross validation.
 \item{ratio_min:} The selected best ratio by cross validation.
 \item{cv_mse:} The mean square error(mse) when family = "gaussian", and use_cv = TRUE.
 \item{cv_dev:} The deviance(dev) when family = "binomial", and use_cv = TRUE.
 \item{cv_auc:} The area under the curve of sensitivity specificity when family = "binomial", and use_cv = TRUE.
 \item{selected_vars:} For inference or post-selection inference, we output the inference results by a list. \itemize{
 \item{position:} The index of nonzero positions, the index comes from X = (A,Z,W).
 \item{name:} The feature name of nonzero positions. If there is no default name, we name it after Ai, Zi, Wi.
 \item{coef:} The coefficients of nonzero positions.
 \item{variance:} The variances for features with none penalty inference or for selected features with post-selection inference.
 \item{variance_covariance:} The variance-covariance matrix for features with none penalty inference or for selected features with post-selection inference.
 \item{pval:} For p values for nonzero positions.
 \item{FDR_adjust_position:} The FDR adjusted positions passing significant level 0.05 after BH adjustment (Benjamini & Hochberg).
 \item{FDR_adjust_name:} The feature name based on FDR_adjust_position.
 }
 }
}
\description{
htlgmm fits a generalized linear model via penalized generalized method of moments,
i.e. Heterogeneous Transfer Learning via Generalized Method of Moments.
The input requires main study and external study.
cv.htlgmm does k-fold cross validation for htlgmm.
}
\details{
Cross validation for htlgmm.
}
