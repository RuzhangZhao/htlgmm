% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/htlgmm.R
\name{cv.htlgmm}
\alias{cv.htlgmm}
\title{Cross validation for htlgmm.}
\usage{
cv.htlgmm(
  y,
  Z,
  W = NULL,
  study_info = NULL,
  family = "gaussian",
  A = 1,
  penalty_type = "lasso",
  initial_with_type = "ridge",
  beta_initial = NULL,
  use_sparseC = FALSE,
  inference = FALSE,
  tune_ratio = FALSE,
  validation_type = "cv",
  type.measure = "default",
  nfolds = 10,
  remove_penalty_Z = FALSE,
  remove_penalty_W = FALSE,
  fix_lambda = NULL,
  lambda_list = NULL,
  fix_ratio = NULL,
  ratio_lower = NULL,
  ratio_upper = NULL,
  ratio_count = 10,
  ratio_range = NULL,
  gamma_adaptivelasso = 1/2,
  summary_type = "multi",
  holdout_p = 0.2,
  seed.use = 97
)
}
\arguments{
\item{y}{The y for response variable, which can be continouse or binary.}

\item{Z}{The overlapping features}

\item{W}{The mismatched features only in internal data, the default is NULL.}

\item{study_info}{The  only from external data,
which can be summarized in the type of multivariate version or univariate version.}

\item{family}{The family is chosen from c("gaussian","binomial"). Linear regression for "gaussian" and logistic regression for "binomial".}

\item{A}{Usually used in "binomial" family, e.g. the intercept term for logistic regression, where the default is 1.
Usually not used in "gaussian" family.}

\item{penalty_type}{The penalty type for htlgmm, chosen from c("lasso","adaptivelasso","ridge"). The default is "lasso".}

\item{initial_with_type}{Get initial estimation for beta using internal data only
by cross validation using penalty regression, chosen from c("ridge","lasso"). The default is "ridge".}

\item{beta_initial}{The initial estimation for beta if a consistent estimator is available.
E.g., one may input htlgmm result as beta_initial for more rounds to refine the final estimation.
The default is NULL, and internal data is used for initial estimation.}

\item{use_sparseC}{Whether to use approximate version of weighting matrix C.
If approximation, use the diagonal of inverse of C(inv_C) to approximate the inv_C. The default is FALSE.
When internal data sample size is limited, use_sparseC = TRUE is recommended.
When internal data sample size is large enough, use_sparseC = FALSE is recommended.}

\item{inference}{Whether to do post-selection inference, only work for adaptivelasso. The default is FALSE.}

\item{tune_ratio}{Whether to use two-lambda stratgey. The default is TRUE.}

\item{validation_type}{How to perform validation to find the best lamdba or ratio.
Select from c("cv","holdout"). The default is "cv".}

\item{type.measure}{Select from c("default", "mse", "deviance", "auc"). Default is mse(liner), deviance(logistic). auc is another choice for binary response variable..}

\item{nfolds}{The fold number for cross validation. Only work for validation_type = "cv".The default is 10.}

\item{remove_penalty_Z}{Not penalize X if it is TRUE. The default is FALSE.}

\item{remove_penalty_W}{Not penalize W if it is TRUE. The default is FALSE.}

\item{fix_lambda}{Without cross validation, fix the lambda. The default is NULL.}

\item{lambda_list}{Customize the input lambda list for validation. The default is NULL.}

\item{fix_ratio}{The fixed ratio of X for two-lambda strategy. The default is NULL. If it is NULL, select the best ratio via cross validation or holdout validation.}

\item{ratio_lower}{The lower bound for ratio range. The default is NULL.}

\item{ratio_upper}{The upper bound for ratio range. The default is NULL.}

\item{ratio_count}{The lengte of ratio list. The default is 10.}

\item{ratio_range}{The ratio range if it is preset. The default is NULL.}

\item{gamma_adaptivelasso}{The gamma for adaptive lasso. Select from c(1/2,1,2). The default is 1/2.}

\item{summary_type}{The summary statistics type, chosen from c("multi","uni"), where the default is "multi".}

\item{holdout_p}{The holdout validation data proportion. Only work for validation_type = "holdout". The default is 0.2.}

\item{seed.use}{The seed for  97.}
}
\value{
\itemize{
 \item{beta:} The target coefficient estimation.
 \item{lambda_list:} The lambda list for validation (cross validation or holdout validation).
 \item{ratio_list:} The ratio list for validation (cross validation or holdout validation).
 \item{holdout_mse:} The mean square error(mse) when family = "gaussian", and validation_type = "holdout".
 \item{cv_mse:} The mean square error(mse) when family = "gaussian", and validation_type = "cv".
 \item{holdout_dev:} The deviance(dev) when family = "binomial", and validation_type = "holdout".
 \item{cv_dev:} The deviance(dev) when family = "binomial", and validation_type = "cv".
 \item{cv_auc:} The area under the curve of sensitivity specificity when family = "binomial", and validation_type = "cv".
 \item{lambda_min:} The selected best lambda.
 \item{ratio_min:} The selected best ratio.
 \item{corrected_pos:} For post-selection inference, they are the corrected position passing significant level 0.05 after BH adjustment (Benjamini & Hochberg).
 \item{nonzero_pos:} For estimated beta, the nonzero positions.
 \item{pval:} For nonzero_pos, the calculated p values.
 \item{nonzero_var:} For nonzero_pos, the calculated variances.
}
}
\description{
htlgmm fits a generalized linear model via penalized generalized method of moments,
i.e. Heterogeneous Transfer Learning via Generalized Method of Moments.
The input requires main study and external study.
cv.htlgmm does k-fold cross validation for htlgmm.
}
\details{
Cross validation for htlgmm.
}
