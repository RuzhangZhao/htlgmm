% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/htlgmm.R
\name{htlgmm}
\alias{htlgmm}
\title{htlgmm:}
\usage{
htlgmm(
  y,
  Z,
  W = NULL,
  study_info = NULL,
  A = "default",
  penalty_type = "none",
  family = "gaussian",
  initial_with_type = "glm",
  beta_initial = NULL,
  alpha = NULL,
  hat_thetaA = NULL,
  V_thetaA = NULL,
  use_offset = FALSE,
  robust = FALSE,
  remove_penalty_Z = FALSE,
  remove_penalty_W = FALSE,
  inference = TRUE,
  fix_C = NULL,
  refine_C = FALSE,
  sqrt_matrix = "cholesky",
  fix_lambda = NULL,
  lambda_list = NULL,
  fix_ratio = NULL,
  fix_weight = NULL,
  gamma_adaptivelasso = 1/2,
  use_sparseC = TRUE,
  seed.use = 97,
  output_all_betas = FALSE
)
}
\arguments{
\item{y}{The outcome variable, which can be continuous, binary or time-to-event data. For coxph model, y should be a list with two items including 'time' and 'event'.}

\item{Z}{The overlapping features in both main and external studies.}

\item{W}{The unmatched features only in main study, the default is NULL. Without W, the problem is degenerated to problem similar to meta-analysis.}

\item{study_info}{The trained model from external study, including estimated coefficients, estimated variance-covariance matrix and sample size.
The 'study_info' is in the format of list. The first item is 'Coeff', the second item is 'Covariance', and the third item (optional) is 'Sample_size'.
E.g. study_info = list(list("Coeff"=coeff,"Covariance"=covariance,"Sample_size"=sample_size))}

\item{A}{The covariates for study-specific adjustment. The default is 'default', which is 'NULL' for 'gaussian' family or 'cox' family, '1' for 'binomial' family.
Other than c('default',NULL,1), A must be a matrix whose dimension is the same as the sample dimension or Z and W.
For continuous variable, we suggest scaling the features Z, W to eliminate intercept term.  If 'A = NULL', there is no intercept term included.
For binary variable, we use intercept term by 'A=1' to adjust for different binary trait ratios in main and external studies.
If there is only intercept term in A, we use 'A=1'.
A are the features working for adjustment in reduced model, but A is not summarized in summary statistics(input:study_info).}

\item{penalty_type}{The penalty type for htlgmm, chosen from c("none","lasso","adaptivelasso","ridge","elasticnet"). The default is "adaptivelasso".
If 'penalty_type = 'none' ', we use without penalty. (For continuous y, we use ordinary least square, and for binary y, we use logistic regression without penalty.)}

\item{family}{The family is chosen from c("gaussian","binomial"). Linear regression for "gaussian" and logistic regression for "binomial".}

\item{initial_with_type}{Get initial estimation for beta using main study data only
by cross validation using (penalty) regression, chosen from c("ridge","lasso","glm"). The default is "ridge". If penalty_type = 'glm',
for continuous y, we use ordinary least square, and for binary y, we use logistic regression without penalty.)}

\item{beta_initial}{The initial estimation for beta if a consistent estimator is available.
E.g., one may input htlgmm result as beta_initial for more rounds to refine the final estimation.
The default is NULL, and main study is used for initial estimation according to 'initial_with_type'.}

\item{alpha}{The elasticnet mixing parameter, between 0 and 1, which is corresponding to the alpha for glmnet. Only used when penalty_type == 'elasticnet'.}

\item{hat_thetaA}{If A is not NULL, one can provide hat_thetaA as the input. If 'hat_thetaA = NULL', we estimate hat_thetaA with glm by main study.}

\item{V_thetaA}{If A is not NULL, one can provide V_thetaA as the input. If 'V_thetaA = NULL', we estimate V_thetaA with glm by main study.}

\item{use_offset}{Whether to use offset regarding the external model estimated coefficient. The default is FALSE.}

\item{robust}{Whether to apply sandwich formula to compute the variance-covariance matrix of hat_thetaA.The default is TRUE.
For coxph model, robust is also about whether we apply the robust variance for the estimating equations.}

\item{remove_penalty_Z}{Not penalize Z if it is TRUE. The default is FALSE.}

\item{remove_penalty_W}{Not penalize W if it is TRUE. The default is FALSE.}

\item{inference}{Whether to do inference without penalty or post-selection inference with adaptive lasso penalty. The default is TRUE.}

\item{fix_C}{When fix_C = NULL, the optimal C is computed. When user wants to customize the fix_C, please match its dimension as dim(A)+2*dim(Z)+dim(W) and make sure it is positive definite.}

\item{refine_C}{When computing the variance, whether recompute the weighting matrix C using final estimated beta. The default is FALSE.}

\item{sqrt_matrix}{The method to split weighting matrix into square root matrix. Select from c('svd','cholesky'), where 'cholesky' generates faster computation.}

\item{fix_lambda}{Without cross validation, fix the lambda. The default is NULL.}

\item{lambda_list}{Customize the input lambda list for validation. The default is NULL to generate lambda list according to glmnet.}

\item{fix_ratio}{The fixed ratio for two-lambda strategy. The ratio is multiplied for Z features. The default is NULL. If it is NULL, select the best ratio via cross validation or holdout validation.}

\item{fix_weight}{The fixed weight for weighting matrix of external study.}

\item{gamma_adaptivelasso}{The gamma for adaptive lasso. Select from c(1/2,1,2). The default is 1/2.}

\item{use_sparseC}{Whether to use approximate version of weighting matrix C using only diagonal terms as nonzeros.
If approximation, use the diagonal of inverse of C(inv_C) to approximate the inv_C. The default is TRUE.
When main study sample size is limited, use_sparseC = TRUE is recommended.
When main study sample size is large enough, use_sparseC = FALSE is recommended.}

\item{seed.use}{The seed for  97.}

\item{output_all_betas}{Output all betas.}
}
\value{
\itemize{
 \item{beta:} The target coefficient estimation, the features will go in the order of (A,Z,W).
 \item{lambda_list:} The lambda list for cross validation.
 \item{ratio_list:} The ratio list for validation (cross validation or holdout validation).
 \item{fix_lambda:} If the fix_lambda is not null, we output fix_lambda.
 \item{fix_ratio:} If the fix_ratio is not null, we output fix_ratio.
 \item{selected_vars:} For inference or post-selection inference, we output the inference results by a list. \itemize{
 \item{position:} The index of nonzero positions, the index comes from X = (A,Z,W).
 \item{name:} The feature name of nonzero positions. If there is no default name, we name it after Ai, Zi, Wi.
 \item{coef:} The coefficients of nonzero positions.
 \item{variance:} The variances for features with glm inference, for selected features with post-selection inference.
 \item{pval:} For p values for nonzero positions.
 \item{FDR_adjust_position:} The FDR adjusted positions passing significant level 0.05 after BH adjustment (Benjamini & Hochberg).
 \item{FDR_adjust_name:} The feature name based on FDR_adjust_position.
 }
 }
}
\description{
htlgmm fits a generalized linear model or cox proportional hazard model via penalized generalized method of moments,
i.e. Heterogeneous Transfer Learning via Generalized Method of Moments.
The input requires a main study and an external study.
}
\details{
htlgmm: Heterogeneous Transfer Learning via generalized method of moments(GMM).
}
